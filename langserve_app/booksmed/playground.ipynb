{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the key from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import asyncio\n",
    "from fastapi import FastAPI, Query\n",
    "\n",
    "from langchain.llms import OpenAI, HuggingFaceHub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceBgeEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.chains import LLMChain, HypotheticalDocumentEmbedder\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.pgvector import PGVector, DistanceStrategy\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "import langchain\n",
    "import os\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# langchain.debug = True\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from typing import List\n",
    "from operator import itemgetter\n",
    "import sys\n",
    "import json\n",
    "from langserve import add_routes\n",
    "\n",
    "\n",
    "\n",
    "from langchain.schema import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "from langchain.document_transformers import LongContextReorder\n",
    "reordering = LongContextReorder()\n",
    "sys.path.append(\"../..\")\n",
    "from do_not_share import CONNECTION_STRING # getting the connection string from to the postgres database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_SPACE_DIR_ = './faiss_doc_space'\n",
    "# DOC_SPACE_DIR_ = '/home/dosisiddhesh/LANGCHAIN_EXP/dummy_faiss_doc_space_OpenAI_GTE'\n",
    "########################################################################################################################\n",
    "# Global Variables\n",
    "llm_query = None\n",
    "llm_hyde = None\n",
    "embeddings = None\n",
    "chain = None\n",
    "db = None\n",
    "retriever = None\n",
    "\n",
    "# #-----------------------------------------------------------------------------------------------------------------------\n",
    "# app = FastAPI(\n",
    "#     title=\"LangChain Server\",\n",
    "#     version=\"1.0\",\n",
    "#     description=\"A simple API server using LangChain's Runnable interfaces\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_n_embedding(hyde_llm_name: str, query_llm_name: str, embedding_name: str, temp_hyde: float, temp_query: float, openai_emb_name= None):\n",
    "    global llm_query\n",
    "    global llm_hyde\n",
    "    global embeddings\n",
    "    global retriever\n",
    "    global db\n",
    "    try:\n",
    "        if embedding_name == \"openai-gpt\":\n",
    "            print(\"f\", openai_emb_name)\n",
    "            embeddings = OpenAIEmbeddings(model=openai_emb_name) # getting the embedding model with dim 384\n",
    "        else:\n",
    "            print(\"Loading HuggingFaceEmbeddings with model name: \", embedding_name)\n",
    "            embeddings = HuggingFaceEmbeddings(model_name=embedding_name)\n",
    "    except Exception as e: \n",
    "        print(\"Error in embedding load: \",e)\n",
    "        embeddings = None\n",
    "        return   \n",
    "    if hyde_llm_name == \"openai-gpt\":\n",
    "        llm_hyde = OpenAI(temperature=temp_hyde)\n",
    "    else:\n",
    "        llm_hyde = HuggingFaceHub(repo_id=hyde_llm_name, model_kwargs={\"temperature\":temp_hyde})\n",
    "    if query_llm_name == \"openai-gpt\":\n",
    "        llm_query= ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=temp_query)\n",
    "    else:\n",
    "        llm_query = HuggingFaceHub(repo_id=query_llm_name,model_kwargs={\"temperature\":temp_query})        \n",
    "    hyde_embedding_gte = HypotheticalDocumentEmbedder.from_llm(llm_hyde, embeddings, prompt_key=\"web_search\")\n",
    "    print(\"HyDe Embedding created\")\n",
    "\n",
    "    embeddings = hyde_embedding_gte\n",
    "\n",
    "    # store = LocalFileStore(\"./cache_gte_pubmed/\")\n",
    "    # cached_hyde_embedding_gte = CacheBackedEmbeddings.from_bytes_store(\n",
    "    #     hyde_embedding_gte, store, \n",
    "    # )\n",
    "    try:\n",
    "        db = PGVector(\n",
    "            connection_string=CONNECTION_STRING,\n",
    "            embedding_function=embeddings,\n",
    "            collection_name=\"my_collection\",\n",
    "            distance_strategy=DistanceStrategy.COSINE,\n",
    "        ) \n",
    "    except Exception as e:\n",
    "        print(\"Error in db creation: \",e)\n",
    "        \n",
    "    print(\"DB created/Loaded\")\n",
    "    retriever = db.as_retriever(search_kwargs={'k':3})\n",
    "    # chain = load_qa_chain( llm=llm_query, chain_type=\"stuff\") #why stuff?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f text-embedding-ada-002\n",
      "HyDe Embedding created\n",
      "DB created/Loaded\n"
     ]
    }
   ],
   "source": [
    "load_model_n_embedding(\n",
    "    hyde_llm_name= \"openai-gpt\", \n",
    "    query_llm_name=\"openai-gpt\", \n",
    "    embedding_name=\"openai-gpt\", \n",
    "    temp_hyde=0.5, \n",
    "    temp_query=0.1, \n",
    "    openai_emb_name= \"text-embedding-ada-002\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "relavent_docs = await retriever.aget_relevant_documents(\"what are the symptoms of pneumonia?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reordered_docs= reordering.transform_documents(relavent_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How should I take ORS to recover from dehydration?\n"
     ]
    }
   ],
   "source": [
    "# template = \"\"\"Follow the Previous chat history: {history_qna}\n",
    "#     Answer the question based only on the following context:\n",
    "#     {context}\n",
    "#     The Question is: {question}\n",
    "#     \"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "\n",
    "Information Context:\n",
    "{context}\n",
    "\n",
    "Based only on the information provided above, without speculating or adding new details, answer the following question:\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "query_template = \"\"\"\n",
    "Context:\n",
    "{history_qna}\n",
    "\n",
    "Rewrite or reframe the following query in the context of the conversation history above:\n",
    "\n",
    "Query:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "query_prompt = PromptTemplate.from_template(query_template)\n",
    "\n",
    "chain1 = (\n",
    "    {\n",
    "        \"history_qna\": itemgetter(\"history_qna\"),\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | query_prompt\n",
    "    | llm_query\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "print(chain1.invoke({\"question\": \"What is procedure of taking this drug\",\n",
    "                \"history_qna\": \"Human: I am having loose motion;\\\n",
    "                                AI: You can take ORS. It will help you to recover from dehydration.\"}))\n",
    "\n",
    "global reordered_docs\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "def format_docs(docs):\n",
    "    reordered_docs = reordering.transform_documents(docs)\n",
    "    return \"\\n\\n\".join([d.page_content for d in reordered_docs])\n",
    "\n",
    "chain = (\n",
    "    {   \n",
    "        # \"history_qna\": itemgetter(\"history_qna\"),\n",
    "        \"question\": chain1,\n",
    "        \"context\": retriever | format_docs, \n",
    "    }\n",
    "    | prompt\n",
    "    | llm_query\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "origianl_answer = chain.invoke({\"question\": \"What is procedure of taking this drug\", \n",
    "              \"history_qna\": \"Human: I am having loose motion;\\\n",
    "                              AI: You can take ORS. It will help you to recover from dehydration.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- temp1 = '''Identify any instances of ambiguity, vagueness, or incomplete information. \n",
    "Then, generate questions to address each identified uncertainty and \n",
    "improve the clarity of the original answer.\n",
    "'''\n",
    "- temp2 = '''Look for speculative statements or instances where the information is not grounded in concrete details.\n",
    " Formulate questions to ask the model for more precise information and to reduce speculation.'''\n",
    "\n",
    "- temp3 = '''Check for any discrepancies or contradictions within the response. \n",
    "Generate questions to resolve these inconsistencies and ensure a coherent and accurate explanation.\n",
    "'''\n",
    "\n",
    "##################### 4\n",
    "- temp4 = ''' Identify and categorize any uncertainty concepts present in the response. \n",
    "Examples include ambiguity, vagueness, incomplete information, speculation, etc.\n",
    "\n",
    "Based on the identified uncertainties, \n",
    "generate questions to ask the model for clarification or additional details. \n",
    "Return question phrases to ask the language model to improve the clarity and reduce uncertainty in the original answer.\n",
    "'''\n",
    "\n",
    "##################### 5\n",
    "- temp5 = '''\n",
    "Consider the context and identify any instances of ambiguity. \n",
    "Generate questions to seek clarity and ensure that the response is precise and unambiguous.\n",
    "'''\n",
    "\n",
    "- temp6 = '''Identify any aspects of the question that the response did not address or left unclear. \n",
    "Generate questions to inquire about these unanswered aspects and fill in the missing details.\n",
    "'''\n",
    "##################### 7\n",
    "- temp7 = '''Identify any areas where the information lacks precision or specificity. \n",
    "Formulate questions to ask the model for more detailed and specific information to enhance\n",
    "the accuracy of the original answer.\n",
    "'''\n",
    "\n",
    "- temp8 = '''Identify any statements that introduce hypothetical scenarios or possibilities.\n",
    "Generate questions to explore these hypotheticals and seek clarification on the likelihood or\n",
    "conditions associated with them.\n",
    "'''\n",
    "\n",
    "\n",
    "| for now let us go with the 4th template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To recover from dehydration, you should take ORS (oral rehydration solution) as directed. The recommended dosage of ORS depends on age. For adults, 2 liters of oral rehydration fluid should be given in the first 24 hours, followed by unrestricted normal fluids with 200 mL of rehydration solution per loose stool or vomit. For children, 30-50 mL/kg of ORS should be given over 3-4 hours. It is best to sip the solution every 5-10 minutes rather than drinking it in large quantities less frequently. Additionally, it is important to continue monitoring blood glucose levels, especially for diabetic patients.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origianl_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "output_parser2 = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser2.get_format_instructions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. What is the recommended dosage of ORS for adults?\\n2. How much rehydration solution should be given per loose stool or vomit for adults?\\n3. What is the recommended dosage of ORS for children?\\n4. How should the ORS solution be consumed - in large quantities less frequently or sipped every 5-10 minutes?\\n5. Are there any specific instructions for diabetic patients regarding ORS consumption?\\n6. Are there any specific instructions for monitoring blood glucose levels during dehydration recovery?'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Foramt Instructions: {format_instructions}\n",
    "template_uncertainity = \"\"\"\n",
    "Given the following generated answer:\n",
    "\n",
    "Answer:\n",
    "{answer}\n",
    "\n",
    "Identify and categorize any uncertainty concepts present in the response. Examples include ambiguity, vagueness, incomplete information, speculation, etc.\n",
    "Based on the identified uncertainties, generate questions to ask the model for clarification or additional details. Return question phrases to ask the language model to improve the clarity and reduce uncertainty in the original answer.\n",
    "\"\"\"\n",
    "template_uncertainity = \"\"\"\n",
    "Given the following generated answer:\n",
    "\n",
    "Answer:\n",
    "{answer}\n",
    "\n",
    "Identify and categorize any uncertainty concepts present in the response. Uncertainty can be defined by ambiguity, vagueness, incomplete information, speculation, etc.\n",
    "Based on the identified uncertainties, generate questions to ask the model for clarification or additional details. \n",
    "\"Return ONLY\" the question phrases to ask the language model to improve the clarity and reduce uncertainty in the original answer.\n",
    "\"\"\"\n",
    "prompt_uncertainty = PromptTemplate.from_template(\n",
    "    template= template_uncertainity,\n",
    "    # partial_variables={'format_instructions': format_instructions}\n",
    "    )\n",
    "\n",
    "chain_uncertainty = (\n",
    "    {\n",
    "        \"answer\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt_uncertainty\n",
    "    | llm_query\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "uncertainity_answer = chain_uncertainty.invoke({\"answer\": origianl_answer})\n",
    "uncertainity_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. What is the recommended dosage of ORS for adults?',\n",
       " '2. How much rehydration solution should be given per loose stool or vomit for adults?',\n",
       " '3. What is the recommended dosage of ORS for children?',\n",
       " '4. How should the ORS solution be consumed - in large quantities less frequently or sipped every 5-10 minutes?',\n",
       " '5. Are there any specific instructions for diabetic patients regarding ORS consumption?',\n",
       " '6. Are there any specific instructions for monitoring blood glucose levels during dehydration recovery?']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncertainity_answers = uncertainity_answer.split(\"\\n\")\n",
    "uncertainity_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunnableParallel to find the answers parallelly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Question: What is the recommended dosage of ORS for adults?\\nAnswer: The recommended dosage of ORS for adults is 200-400 mL after each loose stool or vomiting episode.',\n",
       " 'Question: How much rehydration solution should be given per loose stool or vomit for adults?\\nAnswer: The recommended amount of rehydration solution to be given per loose stool or vomit for adults is approximately 200-400 ml (6-13 ounces) per episode.',\n",
       " 'Question: What is ORS?\\nAnswer: ORS stands for Oral Rehydration Solution, which is a special drink used to treat dehydration caused by diarrhea or vomiting.\\nQuestion: Why is ORS recommended for children?\\nAnswer: ORS is recommended for children because it helps replace the fluids and electrolytes lost during diarrhea or vomiting, preventing dehydration.\\nQuestion: How does ORS work?\\nAnswer: ORS works by providing the body with a balanced amount of water, salts, and sugar. This helps the body absorb fluids more effectively and restore the electrolyte balance.\\nQuestion: Is ORS safe for children?\\nAnswer: Yes, ORS is safe for children. It is specifically formulated to meet the needs of children and is recommended by healthcare professionals for treating dehydration.\\nQuestion: What is the dosage of ORS for children?\\nAnswer: The recommended dosage of ORS for children depends on their age and weight. It is best to consult a healthcare professional for specific dosage instructions.\\nQuestion: How should ORS be administered to children?\\nAnswer: ORS should be administered to children in small, frequent sips using a spoon, cup, or oral syringe. It is important to follow the instructions provided by healthcare professionals for proper administration.\\nQuestion: Are there any side effects of ORS in children?\\nAnswer: Generally, ORS does not have any significant side effects. However, in rare cases, it may cause mild stomach upset or nausea. If any unusual symptoms occur, it is advisable to consult a healthcare professional.',\n",
       " 'Question: How should the ORS solution be consumed - in large quantities less frequently or sipped every 5-10 minutes?\\nAnswer: The ORS solution should be sipped every 5-10 minutes rather than consumed in large quantities less frequently.',\n",
       " 'Question: Are there any specific instructions for diabetic patients regarding ORS consumption?\\nAnswer: Yes, there are specific instructions for diabetic patients regarding ORS consumption. Diabetic patients should consult with their healthcare provider before consuming ORS. They may need to monitor their blood sugar levels more frequently while consuming ORS and adjust their insulin or medication dosage accordingly. It is important for diabetic patients to carefully read the label of the ORS product and choose one that is sugar-free or low in sugar. They should also consider the carbohydrate content of the ORS and factor it into their meal plan.',\n",
       " 'Question: Are there any specific instructions for monitoring blood glucose levels during dehydration recovery?\\nAnswer: It is important to monitor blood glucose levels during dehydration recovery, especially if you have diabetes or are at risk for developing diabetes. Dehydration can affect blood sugar levels, so it is recommended to check your blood glucose levels regularly. Additionally, make sure to stay hydrated and follow any specific instructions given by your healthcare provider regarding monitoring and managing your blood glucose levels during dehydration recovery.']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "#******************************************************** Directly asking the question to the model ******************************************************\n",
    "# chain1 = (\n",
    "#     {\n",
    "#         \"question_uncertainty\": RunnablePassthrough(),\n",
    "#     }\n",
    "#     | ChatPromptTemplate.from_template(\"Please clarify more about following {question_uncertainty}. Return question answer pairs in the following format: Question: Answer:\")\n",
    "#     | llm_query \n",
    "#     | output_parser\n",
    "# )\n",
    "\n",
    "# question_input = [{\"question_uncertainty\": q} for q in uncertainity_answers]\n",
    "\n",
    "\n",
    "# answer_uncertainty = chain1.batch(question_input)\n",
    "\n",
    "# answer_uncertainty\n",
    "\n",
    "#******************************************************** Using RAG (Retreiver) to get the answer ******************************************************\n",
    "\n",
    "template_uncertainity_rag = '''\n",
    "Information Context:\n",
    "{context}\n",
    "\n",
    "Based only on the information provided above, without speculating or adding new details, answer the following question.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "Return question answer pairs in the following format: Question: Answer:\n",
    "'''\n",
    "\n",
    "prompt_uncertainty_rag = PromptTemplate.from_template(template= template_uncertainity_rag)\n",
    "\n",
    "chain_uncertainty_answer = (\n",
    "    {   \n",
    "        \"question\": chain1,\n",
    "        \"context\": retriever | format_docs, \n",
    "    }\n",
    "    | prompt_uncertainty_rag\n",
    "    | llm_query\n",
    "    | output_parser\n",
    ")\n",
    "question_input = [{\"question_uncertainty\": q} for q in uncertainity_answers]\n",
    "answer_uncertainty = chain_uncertainty_answer.batch(question_input)\n",
    "answer_uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To recover from dehydration, it is recommended to take ORS (oral rehydration solution) as directed. The dosage of ORS depends on age. For adults, it is recommended to consume 2 liters of oral rehydration fluid in the first 24 hours, followed by unrestricted normal fluids with 200 mL of rehydration solution per loose stool or vomit. For children, the recommended dosage is 30-50 mL/kg of ORS over 3-4 hours. It is best to sip the solution every 5-10 minutes rather than drinking it in large quantities less frequently. ORS is a special drink used to treat dehydration caused by diarrhea or vomiting. It works by providing the body with a balanced amount of water, salts, and sugar, helping the body absorb fluids more effectively and restore the electrolyte balance. ORS is safe for children and is specifically formulated to meet their needs. It is important to administer ORS to children in small, frequent sips using a spoon, cup, or oral syringe. While ORS generally does not have significant side effects, it may cause mild stomach upset or nausea in rare cases. Diabetic patients should consult with their healthcare provider before consuming ORS. They may need to monitor their blood sugar levels more frequently and adjust their insulin or medication dosage accordingly. It is important for diabetic patients to choose a sugar-free or low-sugar ORS product and consider the carbohydrate content in their meal plan. During dehydration recovery, it is important to monitor blood glucose levels, especially for diabetic patients or those at risk for developing diabetes. Dehydration can affect blood sugar levels, so regular monitoring is recommended. It is also important to stay hydrated and follow any specific instructions provided by healthcare providers for monitoring and managing blood glucose levels during dehydration recovery.'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_final = \"\"\"\n",
    "Given the original base answer and the answers for the uncertainty questions, generate a final answer that is more complete and clear than the original answer.\n",
    "Original Answer: \n",
    "{original_answer}\n",
    "Uncertainty Answers:\n",
    "{uncertainty_answers}\n",
    "Final Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_final = PromptTemplate.from_template(template_final)\n",
    "\n",
    "chain_final = (\n",
    "    {\n",
    "        \"original_answer\": RunnablePassthrough(),\n",
    "        \"uncertainty_answers\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt_final\n",
    "    | llm_query\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "final_answer = chain_final.invoke({\"original_answer\": origianl_answer, \"uncertainty_answers\": answer_uncertainty})\n",
    "\n",
    "final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To recover from dehydration, you should take ORS (oral rehydration solution) as directed. The recommended dosage of ORS depends on age. For adults, 2 liters of oral rehydration fluid should be given in the first 24 hours, followed by unrestricted normal fluids with 200 mL of rehydration solution per loose stool or vomit. For children, 30-50 mL/kg of ORS should be given over 3-4 hours. It is best to sip the solution every 5-10 minutes rather than drinking it in large quantities less frequently. Additionally, it is important to continue monitoring blood glucose levels, especially for diabetic patients.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origianl_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only for practice purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the results from pubmed database \n",
    "\n",
    "It is giving only the abstract title and not the full text\n",
    "\n",
    "eg: \n",
    "```[Document(page_content='# ArticleTitle\\nStrategies for the prevention and management of coronavirus disease 2019.\\n AbstractText\\n\\n AuthorList\\nGuan, Wei-Jie, Chen, Rong-Chang, Zhong, Nan-Shan\\n ArticleId\\n13993003.00597-2020\\n PubMedPubDate\\n2020-3-8'),\n",
    " Document(page_content='# ArticleTitle\\nPrevention is the best treatment.\\n AbstractText\\n\\n AuthorList\\nSchneider, H S\\n ArticleId\\nMissing ArticleId\\n PubMedPubDate\\n1968-8-1'),\n",
    " Document(page_content='# ArticleTitle\\nPrevention and Control of Coronavirus Disease 2019: Where Do We Go From Here?\\n AbstractText\\n\\n AuthorList\\nNeuzil, Kathleen M\\n ArticleId\\n6520891\\n PubMedPubDate\\n2022-1-20')]\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #-----------------------------------------------------------------------------------------------------------------------\n",
    "# app = FastAPI(\n",
    "#     title=\"LangChain Server\",\n",
    "#     version=\"1.0\",\n",
    "#     description=\"A simple API server using LangChain's Runnable interfaces\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_n_embedding(hyde_llm_name: str, query_llm_name: str, embedding_name: str, temp_hyde: float, temp_query: float, openai_emb_name= None):\n",
    "    global llm_query\n",
    "    global llm_hyde\n",
    "    global embeddings\n",
    "    global retriever\n",
    "    global db\n",
    "    try:\n",
    "        if embedding_name == \"openai-gpt\":\n",
    "            embeddings = OpenAIEmbeddings(openai_emb_name) # getting the embedding model with dim 384\n",
    "        else:\n",
    "            print(\"Loading HuggingFaceEmbeddings with model name: \", embedding_name)\n",
    "            embeddings = HuggingFaceEmbeddings(model_name=embedding_name)\n",
    "    except Exception as e: \n",
    "        print(\"Error in embedding load: \",e)\n",
    "        embeddings = None\n",
    "        return   \n",
    "    if hyde_llm_name == \"openai-gpt\":\n",
    "        llm_hyde = OpenAI(temperature=temp_hyde)\n",
    "    else:\n",
    "        llm_hyde = HuggingFaceHub(repo_id=hyde_llm_name, model_kwargs={\"temperature\":temp_hyde})\n",
    "    if query_llm_name == \"openai-gpt\":\n",
    "        llm_query= ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=temp_query)\n",
    "    else:\n",
    "        llm_query = HuggingFaceHub(repo_id=query_llm_name,model_kwargs={\"temperature\":temp_query})        \n",
    "    hyde_embedding_gte = HypotheticalDocumentEmbedder.from_llm(llm_hyde, embeddings, prompt_key=\"web_search\")\n",
    "    print(\"HyDe Embedding created\")\n",
    "\n",
    "    embeddings = hyde_embedding_gte\n",
    "\n",
    "    # store = LocalFileStore(\"./cache_gte_pubmed/\")\n",
    "    # cached_hyde_embedding_gte = CacheBackedEmbeddings.from_bytes_store(\n",
    "    #     hyde_embedding_gte, store, \n",
    "    # )\n",
    "    try:\n",
    "        db = PGVector(\n",
    "            connection_string=CONNECTION_STRING_2,\n",
    "            embedding_function=embeddings,\n",
    "            collection_name=\"pubmed\",\n",
    "            distance_strategy=DistanceStrategy.COSINE,\n",
    "        ) \n",
    "    except Exception as e:\n",
    "        print(\"Error in db creation: \",e)\n",
    "        \n",
    "    print(\"DB created/Loaded\")\n",
    "    retriever = db.as_retriever(search_kwargs={'k':3})\n",
    "    # chain = load_qa_chain( llm=llm_query, chain_type=\"stuff\") #why stuff?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HuggingFaceEmbeddings with model name:  thenlper/gte-small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dosisiddhesh/LANGCHAIN_EXP/env_lc_3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyDe Embedding created\n",
      "DB created/Loaded\n"
     ]
    }
   ],
   "source": [
    "load_model_n_embedding(\"openai-gpt\", \"openai-gpt\", \"thenlper/gte-small\", 0.9, 0.1, \n",
    "                    #    openai_emb_name = 'text-embedding-ada-002'\n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='# ArticleTitle\\nStrategies for the prevention and management of coronavirus disease 2019.\\n AbstractText\\n\\n AuthorList\\nGuan, Wei-Jie, Chen, Rong-Chang, Zhong, Nan-Shan\\n ArticleId\\n13993003.00597-2020\\n PubMedPubDate\\n2020-3-8'),\n",
       " Document(page_content='# ArticleTitle\\nPrevention is the best treatment.\\n AbstractText\\n\\n AuthorList\\nSchneider, H S\\n ArticleId\\nMissing ArticleId\\n PubMedPubDate\\n1968-8-1'),\n",
       " Document(page_content='# ArticleTitle\\nPrevention and Control of Coronavirus Disease 2019: Where Do We Go From Here?\\n AbstractText\\n\\n AuthorList\\nNeuzil, Kathleen M\\n ArticleId\\n6520891\\n PubMedPubDate\\n2022-1-20')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# #-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "query = \"What is the best treatment for COVID-19?\"\n",
    "history_qna = []\n",
    "\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dosisiddhesh/LANGCHAIN_EXP/env_lc_3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m dbx \u001b[38;5;241m=\u001b[39m PGVector(\n\u001b[1;32m      3\u001b[0m             connection_string\u001b[38;5;241m=\u001b[39mCONNECTION_STRING_2,\n\u001b[1;32m      4\u001b[0m             embedding_function\u001b[38;5;241m=\u001b[39membeddingx,\n\u001b[1;32m      5\u001b[0m             collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpubmed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m             distance_strategy\u001b[38;5;241m=\u001b[39mDistanceStrategy\u001b[38;5;241m.\u001b[39mCOSINE,\n\u001b[1;32m      7\u001b[0m         )\n\u001b[1;32m      8\u001b[0m retrieverx \u001b[38;5;241m=\u001b[39m dbx\u001b[38;5;241m.\u001b[39mas_retriever(search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m3\u001b[39m})\n\u001b[0;32m----> 9\u001b[0m docsx \u001b[38;5;241m=\u001b[39m retrieverx\u001b[38;5;241m.\u001b[39mget_relevant_documents(\u001b[43mquery\u001b[49m)\n\u001b[1;32m     10\u001b[0m docsx\n",
      "\u001b[0;31mNameError\u001b[0m: name 'query' is not defined"
     ]
    }
   ],
   "source": [
    "embeddingx = HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\")\n",
    "dbx = PGVector(\n",
    "            connection_string=CONNECTION_STRING_2,\n",
    "            embedding_function=embeddingx,\n",
    "            collection_name=\"pubmed\",\n",
    "            distance_strategy=DistanceStrategy.COSINE,\n",
    "        )\n",
    "retrieverx = dbx.as_retriever(search_kwargs={'k':3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='# ArticleTitle\\nTreatment of pneumonia.\\n AbstractText\\n\\n AuthorList\\nGREGOIRE, F\\n ArticleId\\nPMC1937668\\n PubMedPubDate\\n1960-1-16'),\n",
       " Document(page_content='# ArticleTitle\\n[Treatment of pneumonia].\\n AbstractText\\n\\n AuthorList\\nGREGOIRE, F\\n ArticleId\\nMissing ArticleId\\n PubMedPubDate\\n1960-1-1'),\n",
       " Document(page_content='# ArticleTitle\\nTreatment of pneumonia.\\n AbstractText\\n\\n AuthorList\\nADAMS, J M\\n ArticleId\\nMissing ArticleId\\n PubMedPubDate\\n1951-3-1')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the best treatment for pneumonia?\"\n",
    "\n",
    "docsx = retrieverx.get_relevant_documents(query)\n",
    "docsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='# ArticleTitle\\nTreatment of pneumonia.\\n AbstractText\\n\\n AuthorList\\nGREGOIRE, F\\n ArticleId\\nPMC1937668\\n PubMedPubDate\\n1960-1-16'),\n",
       " Document(page_content='# ArticleTitle\\n[Treatment of pneumonia].\\n AbstractText\\n\\n AuthorList\\nGREGOIRE, F\\n ArticleId\\nMissing ArticleId\\n PubMedPubDate\\n1960-1-1'),\n",
       " Document(page_content='# ArticleTitle\\nTreatment of pneumonia.\\n AbstractText\\n\\n AuthorList\\nADAMS, J M\\n ArticleId\\nMissing ArticleId\\n PubMedPubDate\\n1951-3-1')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbx.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
